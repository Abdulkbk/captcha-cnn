{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c36cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f82ef83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CONTRO~1\\AppData\\Local\\Temp/ipykernel_6644/4140000702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31aef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = '../images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2b827 = mpimg.imread(img_path + '2b827.png')\n",
    "img_2cg58 = mpimg.imread(img_path + '2cg58.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "plt.imshow(img_2b827)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "plt.imshow(img_2cg58)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad54466",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2cg58.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6921db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2b827.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b92ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perf_metrics(predictions, ground_truth):\n",
    "    if predictions.shape == ground_truth.shape:\n",
    "        return np.sum(predictions == ground_truth) / (predictions.shape[0] * predictions.shape[1])\n",
    "    else:\n",
    "        raise Exception('Error: The size of the arrays does not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566de4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "vocabulary = {'2','3','4','5','6','7','8','b','c','d','e','f','g','m','n','p','w','x','y'}\n",
    "char_to_num = {'2':0,'3':1,'4':2,'5':3,'6':4,'7':5,'8':6,'b':7,'c':8,'d':9,'e':10,'f':11,'g':12,'m':13,'n':14,'p':15,'w':16,'x':17,'y':18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5596b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Function\n",
    "\n",
    "def encode_single_sample(img_path, label, crop=False):\n",
    "    # Read image file and returns a tensor with dtype=string\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # Decode and convert to grayscale (this conversion does not cause any information lost and reduces the size of the tensor)\n",
    "    # This decode function returns a tensor with dtype=uint8\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # Scales and returns a tensor with dtype=float32\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
    "    # Crop and resize to the original size : \n",
    "    # top-left corner = offset_height, offset_width in image = 0, 25 \n",
    "    # lower-right corner is at offset_height + target_height, offset_width + target_width = 50, 150\n",
    "    if (crop):\n",
    "        img = tf.image.crop_to_bounding_box(img, offset_height=0, offset_width=25, target_height=50, target_width=125)\n",
    "        img = tf.image.resize(img, size=[50,200], method='bilinear', preserve_aspect_ratio=False, antialias=False, name=None)\n",
    "    # Transpose the image because we want the time dimension to correspond to the width of the image.\n",
    "    img = tf.transpose(img, perm=[1, 0, 2]) # REVISIT NEEDED\n",
    "    # Converts the string label into an array with 5 integers. E.g. '6n6gg' is converted into [6,16,6,14,14]\n",
    "    label = list(map(lambda x:char_to_num[x], label))\n",
    "    return img.numpy(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f390a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test and validation data splitting function\n",
    "def create_train_and_validation_datasets(crop=False):\n",
    "    # Loop on all the files to create X whose shape is (1040, 50, 200, 1) and y whose shape is (1040, 5)\n",
    "    X, y = [], []\n",
    "    for _, _, files in os.walk(img_folder):\n",
    "        for f in files:\n",
    "            # To start, let's ignore the jpg images\n",
    "            label = f.split('.')[0]\n",
    "            extension = f.split('.')[1]\n",
    "            if extension == 'png':\n",
    "                img, label = encode_single_sample(img_folder + f, label, crop)\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Splitting our data into test and val datasets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X.reshape(1040, 10000), y, test_size=0.1, shuffle=True, random_state=42)\n",
    "    X_train, X_val = X_train.reshape(936,200,50,1), X_val.reshape(104,200,50,1)\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Model\n",
    "\n",
    "def buid_model():\n",
    "    # Input Layer\n",
    "    input_img = layers.Input(shape=(200, 50, 1), name='image', dtype='float32')\n",
    "    \n",
    "    # First Convolution Block\n",
    "    x = layers.Conv2D(32, (2, 2), activation='relu', kernel_initializer=\"he_normal\", padding=\"same\", name='Conv-1')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), name='MaxPool-1')(x)\n",
    "    \n",
    "    # Second Convolution Block\n",
    "    x = layers.Conv2D(64, (2, 2), activation='relu', kernel_initializer=\"he_normal\", padding=\"same\", name='Conv-2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name='MaxPool-2')(x)\n",
    "    \n",
    "     # We have used two max pool with pool size and strides 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64 --> output volume shape = (50,12,64) \n",
    "    # Reshape to \"split\" the volume in 5 time-steps\n",
    "    x  = layers.Reshape(target_shape=(5, 7680), name='reshape')(x)\n",
    "    \n",
    "    # FC layers\n",
    "    x = layers.Dense(256, activation='relu', name='dense1')(x)\n",
    "    x = layers.Dense(64, activation='relu', name='dense2')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    output = layers.Dense(19, activation='softmax', name='ouput')(x)\n",
    "    \n",
    "    # Define Model\n",
    "    model = keras.models.Model(inputs=input_img, output=output, name='ocr_classifier')\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='acuracy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = buid_model()\n",
    "model.summary()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
